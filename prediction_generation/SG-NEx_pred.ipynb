{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fe4c2-9bcd-482f-8459-cb502d0a7328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8af547-20ce-4557-a174-4fd1b35346a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the .h5 file\n",
    "model = load_model('model_NN_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639c9be-05e1-4bd8-8b0c-4ca4281b4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p data_parsing/data/json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529c689-3ea4-4ba4-8f14-0c048df80ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_A549_directRNA_replicate5_run1/ data_parsing/data/json/SGNex_A549_directRNA_replicate5_run1\n",
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_A549_directRNA_replicate6_run1/ data_parsing/data/json/SGNex_A549_directRNA_replicate6_run1\n",
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_Hct116_directRNA_replicate3_run1/ data_parsing/data/json/SGNex_Hct116_directRNA_replicate3_run1\n",
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_Hct116_directRNA_replicate3_run4/ data_parsing/data/json/SGNex_Hct116_directRNA_replicate3_run4\n",
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_Hct116_directRNA_replicate4_run3/ data_parsing/data/json/SGNex_Hct116_directRNA_replicate4_run3\n",
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_HepG2_directRNA_replicate5_run2/ data_parsing/data/json/SGNex_HepG2_directRNA_replicate5_run2\n",
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_HepG2_directRNA_replicate6_run1/ data_parsing/data/json/SGNex_HepG2_directRNA_replicate6_run1\n",
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_K562_directRNA_replicate4_run1/ data_parsing/data/json/SGNex_K562_directRNA_replicate4_run1\n",
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_K562_directRNA_replicate5_run1/ data_parsing/data/json/SGNex_K562_directRNA_replicate5_run1\n",
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_K562_directRNA_replicate6_run1/ data_parsing/data/json/SGNex_K562_directRNA_replicate6_run1\n",
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_MCF7_directRNA_replicate3_run1/ data_parsing/data/json/SGNex_MCF7_directRNA_replicate3_run1\n",
    "! aws s3 sync --no-sign-request s3://sg-nex-data/data/processed_data/m6Anet/SGNex_MCF7_directRNA_replicate4_run1/ data_parsing/data/json/SGNex_MCF7_directRNA_replicate4_run1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cc32e-ea04-449a-8d7b-eb8b14482769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_acgt_letters(input_string):\n",
    "    letter_counts = dict(Counter(input_string))\n",
    "    acgt_counts = {\n",
    "        'A': letter_counts.get('A', 0),\n",
    "        'C': letter_counts.get('C', 0),\n",
    "        'G': letter_counts.get('G', 0),\n",
    "        'T': letter_counts.get('T', 0),\n",
    "    }\n",
    "    \n",
    "    return acgt_counts\n",
    "\n",
    "\n",
    "def count_data(data_list):\n",
    "    parsed_data = []  \n",
    "    for data in data_list:\n",
    "        for transcript_id, positions in data.items():\n",
    "            for position, details in positions.items():\n",
    "                for sequence, readings in details.items():\n",
    "                    letter_counts = count_acgt_letters(sequence[1:6]) \n",
    "                    for reading in readings:\n",
    "                        value = reading[3:6]\n",
    "                        parsed_data.append([transcript_id, int(position), sequence[1:6],letter_counts['A'], letter_counts['C'], letter_counts['G'], letter_counts['T']] + value)\n",
    "\n",
    "    columns = ['transcript_id', 'position','sequence', 'A', 'C', 'G', 'T', '0 length', '0 sd', '0 mean']\n",
    "\n",
    "    return pd.DataFrame(parsed_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf83d9-420a-4c60-8530-66fec92b362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['data_parsing/data/json/SGNex_A549_directRNA_replicate5_run1/data.json',\n",
    "              'data_parsing/data/json/SGNex_A549_directRNA_replicate6_run1/data.json',\n",
    "              'data_parsing/data/json/SGNex_Hct116_directRNA_replicate3_run1/data.json',\n",
    "              'data_parsing/data/json/SGNex_Hct116_directRNA_replicate3_run4/data.json',\n",
    "              'data_parsing/data/json/SGNex_Hct116_directRNA_replicate4_run3/data.json',\n",
    "              'data_parsing/data/json/SGNex_HepG2_directRNA_replicate5_run2/data.json',\n",
    "              'data_parsing/data/json/SGNex_HepG2_directRNA_replicate6_run1/data.json',\n",
    "              'data_parsing/data/json/SGNex_K562_directRNA_replicate4_run1/data.json',\n",
    "              'data_parsing/data/json/SGNex_K562_directRNA_replicate5_run1/data.json',\n",
    "              'data_parsing/data/json/SGNex_K562_directRNA_replicate6_run1/data.json',\n",
    "              'data_parsing/data/json/SGNex_MCF7_directRNA_replicate3_run1/data.json',\n",
    "              'data_parsing/data/json/SGNex_MCF7_directRNA_replicate4_run1/data.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e67fb-2a11-441b-97f4-0fa030357bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "              \n",
    "              \n",
    "for file_path in file_paths:\n",
    "    # Get the directory path\n",
    "    directory_path = os.path.dirname(file_path)\n",
    "\n",
    "    # Get the folder name\n",
    "    folder_name = os.path.basename(directory_path)\n",
    "    \n",
    "    print(folder_name)\n",
    "\n",
    "    # Create a list to hold the JSON objects\n",
    "    data_list = []\n",
    "\n",
    "    # Open and decompress the gz file, then load the JSON data line by line\n",
    "    with open(file_path, 'rt', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Parse the JSON data for the line and append to data_list\n",
    "            json_obj = json.loads(line.strip())\n",
    "            data_list.append(json_obj)\n",
    "\n",
    "    # Example: Convert the first JSON object to a Pandas DataFrame\n",
    "    df = pd.json_normalize(data_list[0])\n",
    "\n",
    "    df = count_data(data_list)\n",
    "    \n",
    "    df['0 min'] = df['0 mean'] - df['0 sd']*1.96\n",
    "    df['0 max'] = df['0 mean'] + df['0 sd']*1.96\n",
    "    \n",
    "    data = pd.get_dummies(df, columns=['sequence'], prefix='sequence')\n",
    "    \n",
    "    # Apply the function to each row\n",
    "    data['specific_sequence'] = data.apply(extract_specific_sequence, axis=1)\n",
    "\n",
    "    data['1st_pos'] = data['specific_sequence'].apply(lambda x: x[0])\n",
    "    data['2nd_pos'] = data['specific_sequence'].apply(lambda x: x[1])\n",
    "    data['3rd_pos'] = data['specific_sequence'].apply(lambda x: x[2])\n",
    "    data['4th_pos'] = data['specific_sequence'].apply(lambda x: x[3])\n",
    "    data['5th_pos'] = data['specific_sequence'].apply(lambda x: x[4])\n",
    "    seq_col = [col for col in data.columns.tolist() if col.startswith('sequence_')]\n",
    "    data.drop(seq_col, axis=1, inplace=True)\n",
    "    data.drop('specific_sequence', axis=1, inplace=True)\n",
    "    data['1st_pos'] = data['1st_pos'].astype('category')\n",
    "    data['2nd_pos'] = data['2nd_pos'].astype('category')\n",
    "    data['3rd_pos'] = data['3rd_pos'].astype('category')\n",
    "    data['4th_pos'] = data['4th_pos'].astype('category')\n",
    "    data['5th_pos'] = data['5th_pos'].astype('category')\n",
    "\n",
    "    \n",
    "    grouped_data = data.groupby(\"transcript_id\")\n",
    "\n",
    "    # Apply the standardization function to the \"0 mean\" column within each group\n",
    "    data[\"0 mean standardized\"] = grouped_data[\"0 mean\"].transform(standardize_column_mean)\n",
    "    data[\"0 sd standardized\"] = grouped_data[\"0 sd\"].transform(standardize_column_sd)\n",
    "    data[\"0 length standardized\"] = grouped_data[\"0 length\"].transform(standardize_column_mean)\n",
    "\n",
    "    final_predict_dataset = data.drop(columns=['transcript_id','position','0 length', '0 sd', '0 mean', '0 min', '0 max'])\n",
    "\n",
    "    # Perform one-hot encoding for categorical columns\n",
    "    final_predict_dataset = pd.get_dummies(final_predict_dataset, columns=['1st_pos', '2nd_pos', '3rd_pos', '4th_pos', '5th_pos'])\n",
    "\n",
    "\n",
    "    transcript = data[['transcript_id','position']]\n",
    "    data_pred_prob = model.predict(final_predict_dataset)\n",
    "\n",
    "    data_pred_prob = pd.DataFrame(pd.DataFrame(data_pred_prob)[0])\n",
    "    data_pred_prob.columns = ['score']\n",
    "    result_data = pd.merge(transcript, data_pred_prob, left_index=True, right_index=True, how='inner')\n",
    "    agg_functions = {'score': 'mean'}\n",
    "\n",
    "    result_data = result_data.groupby(['transcript_id', 'position']).agg(agg_functions).reset_index()\n",
    "\n",
    "    result_data.to_csv('prediction_generation'+folder_name+'_Result.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m106",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m106"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
