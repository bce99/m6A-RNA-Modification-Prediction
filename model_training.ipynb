{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb689c1-6eb3-4c26-a67d-46d3eaadcbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path1 = 'data_parsing/DSA4266Processed_m6alabel_datainfo.csv'\n",
    "file_path2 = 'data_parsing/Parsed_Data0.csv'\n",
    "\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "m6a_label_df = pd.read_csv(file_path1)\n",
    "direct_RNASeq_data = pd.read_csv(file_path2)\n",
    "\n",
    "m6a_label_df['transcript_position'] = pd.to_numeric(m6a_label_df['transcript_position'], errors='coerce')\n",
    "m6a_label_df['label'] = pd.to_numeric(m6a_label_df['label'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb43a210-bbc1-4a70-bc6b-05fa77d08e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path2 = 'data_parsing/Parsed_Data0.csv'\n",
    "\n",
    "direct_RNASeq_data = pd.read_csv(file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb0b7bb-598c-421b-bfe6-944f0de1c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# loading and merging data]\n",
    "\n",
    "merged_df = pd.merge(direct_RNASeq_data, m6a_label_df, \n",
    "                     left_on=['transcript_id', 'position'], \n",
    "                     right_on=['transcript_id', 'transcript_position'])\n",
    "# Initialize label encoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "284681f5-ca98-4640-a810-b1fcc11ae5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the specific sequence\n",
    "def extract_specific_sequence(row):\n",
    "    sequence_columns = [col for col in row.index if col.startswith('sequence_') and row[col] == 1]\n",
    "    if sequence_columns:\n",
    "        return sequence_columns[0].split('sequence_')[1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to each row\n",
    "merged_df['specific_sequence'] = merged_df.apply(extract_specific_sequence, axis=1)\n",
    "\n",
    "\n",
    "merged_df['1st_pos'] = merged_df['specific_sequence'].apply(lambda x: x[0])\n",
    "merged_df['2nd_pos'] = merged_df['specific_sequence'].apply(lambda x: x[1])\n",
    "merged_df['3rd_pos'] = merged_df['specific_sequence'].apply(lambda x: x[2])\n",
    "merged_df['4th_pos'] = merged_df['specific_sequence'].apply(lambda x: x[3])\n",
    "merged_df['5th_pos'] = merged_df['specific_sequence'].apply(lambda x: x[4])\n",
    "\n",
    "merged_df.head()\n",
    "\n",
    "\n",
    "seq_col = [col for col in merged_df.columns.tolist() if col.startswith('sequence_')]\n",
    "merged_df.drop(seq_col, axis=1, inplace=True)\n",
    "merged_df.drop('specific_sequence', axis=1, inplace=True)\n",
    "merged_df['1st_pos'] = merged_df['1st_pos'].astype('category')\n",
    "merged_df['2nd_pos'] = merged_df['2nd_pos'].astype('category')\n",
    "merged_df['3rd_pos'] = merged_df['3rd_pos'].astype('category')\n",
    "merged_df['4th_pos'] = merged_df['4th_pos'].astype('category')\n",
    "merged_df['5th_pos'] = merged_df['5th_pos'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744145c9-29cb-462e-9f42-263469ee1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Get unique gene IDs\n",
    "unique_gene_ids = merged_df['gene_id'].unique()\n",
    "\n",
    "# Split unique gene IDs into training and test groups\n",
    "train_gene_ids, test_gene_ids = train_test_split(unique_gene_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create training and test datasets\n",
    "train_data = merged_df[merged_df['gene_id'].isin(train_gene_ids)]\n",
    "test_data = merged_df[merged_df['gene_id'].isin(test_gene_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb280ef-d3a5-4029-acb8-7de3d67fa437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into label 0 and label 1\n",
    "label_0_data = train_data[train_data['label'] == 0]\n",
    "label_1_data = train_data[train_data['label'] == 1]\n",
    "\n",
    "# Calculate the number of label 1 samples needed to achieve a ratio\n",
    "desired_ratio = 1 / 1\n",
    "num_label_0 = len(label_0_data)\n",
    "num_label_1_needed = int(num_label_0 * desired_ratio)\n",
    "\n",
    "# Oversample label 1 data to match the desired ratio\n",
    "label_1_oversampled = pd.concat([label_1_data] * (num_label_1_needed // len(label_1_data)), ignore_index=True)\n",
    "\n",
    "# Combine oversampled label 1 data with original label 0 data\n",
    "train_data = pd.concat([label_1_oversampled, label_0_data])\n",
    "\n",
    "# Shuffle the data to randomize the order\n",
    "train_data = train_data.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db18a89a-11c2-4a72-87cc-36b679de65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_train = train_data.groupby(\"gene_id\")\n",
    "\n",
    "# Define a function for standardization\n",
    "def standardize_column_mean(column):\n",
    "    return (column - column.mean()) / column.std()\n",
    "\n",
    "def standardize_column_sd(column):\n",
    "    return column / column.std()\n",
    "\n",
    "# Apply the standardization function to the \"0 mean\" column within each group\n",
    "train_data[\"0 mean standardized\"] = grouped_train[\"0 mean\"].transform(standardize_column_mean)\n",
    "train_data[\"0 sd standardized\"] = grouped_train[\"0 sd\"].transform(standardize_column_sd)\n",
    "train_data[\"0 length standardized\"] = grouped_train[\"0 length\"].transform(standardize_column_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a244e231-e390-4662-8159-a125d52c1948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "grouped_test = test_data.groupby(\"gene_id\")\n",
    "\n",
    "# Apply the standardization function to the \"0 mean\" column within each group\n",
    "test_data[\"0 mean standardized\"] = grouped_test[\"0 mean\"].transform(standardize_column_mean)\n",
    "test_data[\"0 sd standardized\"] = grouped_test[\"0 sd\"].transform(standardize_column_sd)\n",
    "test_data[\"0 length standardized\"] = grouped_test[\"0 length\"].transform(standardize_column_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b4662c-fd79-4466-a3db-81b8e927b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_dataset = train_data.drop(columns=['transcript_id','position','transcript_position','gene_id','0 length', '0 sd', '0 mean', '0 min', '0 max'])\n",
    "final_test_dataset = test_data.drop(columns=['transcript_id','position','transcript_position','gene_id','0 length', '0 sd', '0 mean', '0 min', '0 max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3db224-2010-4a18-9914-f50ec03624bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for categorical columns\n",
    "final_train_dataset = pd.get_dummies(final_train_dataset, columns=['1st_pos', '2nd_pos', '3rd_pos', '4th_pos', '5th_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcfb57fd-8672-47ab-81d4-2406366e067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for categorical columns\n",
    "final_test_dataset = pd.get_dummies(final_test_dataset, columns=['1st_pos', '2nd_pos', '3rd_pos', '4th_pos', '5th_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8269e1db-3352-4269-8b8b-47e6f4ceaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_dataset['y_label'] = final_train_dataset['label']\n",
    "final_train_dataset = final_train_dataset.drop(columns='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cdc4cc5-e70a-4541-a2f6-f002f5b5f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_dataset['y_label'] = final_test_dataset['label']\n",
    "final_test_dataset = final_test_dataset.drop(columns='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb45775-5fd3-48f9-b144-0037626955e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c650e7c0-5da2-49ed-a11f-54f4b8c90823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 11:42:26.116523: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 11:42:26.207486: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-11-09 11:42:26.207508: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-09 11:42:26.756394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-09 11:42:26.756454: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-09 11:42:26.756459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd2d3ccb-cf8c-4e6c-b698-8c2dac97d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = final_test_dataset.drop(columns=['y_label'])# Input features \n",
    "y_test = final_test_dataset['y_label'] # Target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "952cc9ba-f985-4a4e-8d0c-543f444da5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 11:47:09.032190: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 2214978144 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63620/63620 [==============================] - 55s 859us/step - loss: 0.4916 - accuracy: 0.7562\n",
      "Epoch 2/5\n",
      "63620/63620 [==============================] - 55s 858us/step - loss: 0.4889 - accuracy: 0.7572\n",
      "Epoch 3/5\n",
      "63620/63620 [==============================] - 55s 859us/step - loss: 0.4883 - accuracy: 0.7575\n",
      "Epoch 4/5\n",
      "63620/63620 [==============================] - 55s 858us/step - loss: 0.4880 - accuracy: 0.7577\n",
      "Epoch 5/5\n",
      "63620/63620 [==============================] - 55s 864us/step - loss: 0.4878 - accuracy: 0.7578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f792e43c650>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = final_train_dataset.shape[1]-1\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(num_features,)),  # num_features should be the number of features in your data\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'), \n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Assuming binary classification\n",
    "])\n",
    "\n",
    "X = final_train_dataset.drop(columns=['y_label'])# Input features \n",
    "y = final_train_dataset['y_label'] # Target labels\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y,  epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "945f22b2-f502-4397-ba11-8678d2828757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72217/72217 [==============================] - 44s 601us/step - loss: 0.4941 - accuracy: 0.7400\n",
      "72217/72217 [==============================] - 39s 539us/step\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test, y_test)\n",
    "predictions = (model.predict(X_test) >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70b2e920-af50-4ea9-a7ae-8c96de01ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_NN_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7ba670a-da74-4b07-ad2b-37e462b46d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.74      0.84   2209788\n",
      "         1.0       0.12      0.74      0.20    101131\n",
      "\n",
      "    accuracy                           0.74   2310919\n",
      "   macro avg       0.55      0.74      0.52   2310919\n",
      "weighted avg       0.95      0.74      0.82   2310919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m106",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m106"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
